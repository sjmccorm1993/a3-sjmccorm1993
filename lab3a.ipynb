{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3a: Intro to Machine Learning and  Scikit-learn\n",
    "\n",
    "## Overview\n",
    "\n",
    "* [Part 1: What is machine learning, and how does it work?](#Part-1:-What-is-machine-learning,-and-how-does-it-work?)\n",
    "* [Part 2: Machine learning using scikit-learn](#Part-2:-Machine-learning-using-scikit-learn)\n",
    "* [Part 3: Getting started in scikit-learn with the famous iris dataset](#Part-3:-Getting-started-in-scikit-learn-with-the-famous-iris-dataset)\n",
    "* [Part 4: Training a machine learning model with scikit-learn](#Part-4:-Training-a-machine-learning-model-with-scikit-learn)\n",
    "* [Part 5: Comparing machine learning models in scikit-learn](#Part-5:-Comparing-machine-learning-models-in-scikit-learn)\n",
    "\n",
    "\n",
    "## Part 1: What is machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning](images/01_robot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What is machine learning?\n",
    "- What are the two main categories of machine learning?\n",
    "- What are some examples of machine learning?\n",
    "- How does machine learning \"work\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What is machine learning?\n",
    "\n",
    "One definition: \"Machine learning is the semi-automated extraction of knowledge from data\"\n",
    "\n",
    "- **Knowledge from data**: Starts with a question that might be answerable using data\n",
    "- **Automated extraction**: A computer provides the insight\n",
    "- **Semi-automated**: Requires additional decisions by a human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What are the two main categories of machine learning?\n",
    "\n",
    "**1. Supervised learning**: Making predictions using data\n",
    "    \n",
    "- Example: Is a given email \"spam\" or \"ham\"?\n",
    "- There is an outcome we are trying to predict\n",
    "- Uses preexisting examples to try and learn the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spam filter](images/01_spam_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Unsupervised learning**: Extracting structure from data\n",
    "\n",
    "- Example: Segment grocery store shoppers into clusters that exhibit similar behaviors\n",
    "- There is no \"right answer\"\n",
    "- Subsequent study of the segment's behavior may lead to valuable insights and even predictive models based on segment membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Clustering](images/01_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 How does machine learning \"work\"?\n",
    "\n",
    "High-level steps of supervised learning:\n",
    "\n",
    "1. First, train a **machine learning model** using **labeled data**\n",
    "\n",
    "    - *Labeled data* has been labeled with the outcome\n",
    "    - *Machine learning model* learns the relationship between the attributes of the data and its outcome\n",
    "\n",
    "2. Then, make **predictions** on **new data** for which the label is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Supervised learning](images/01_supervised_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of supervised learning is to build a model that \"generalizes\" it's responses, in that it should accurately predict labels given new unlabeled data. In terms of forecasting, it should accurately predict the **future** rather than just the **past**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Questions about machine learning\n",
    "\n",
    "- How do I choose **which attributes** of my data to include in the model?\n",
    "- How do I choose **which model** to use?\n",
    "- How do I **optimize** this model for best performance?\n",
    "- How do I ensure that I'm building a model that will **generalize** to unseen data?\n",
    "- Can I **estimate** how well my model is likely to perform on unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Resources\n",
    "\n",
    "- Book: [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (section 2.1, 14 pages)\n",
    "- Video: [Learning Paradigms](http://work.caltech.edu/library/014.html) (13 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Machine learning using scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scikit-learn logo](images/02_sklearn_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What are the benefits and drawbacks of scikit-learn?\n",
    "- How is scikit-learn organized? \n",
    "- What methods should be used for a particular problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Benefits and drawbacks of scikit-learn\n",
    "\n",
    "#### Benefits:\n",
    "\n",
    "- **Consistent interface** to machine learning models\n",
    "- Provides many **tuning parameters** but with **sensible defaults**\n",
    "- Exceptional **documentation**\n",
    "- Rich set of functionality for **companion tasks**\n",
    "- **Active community** for development and support\n",
    "\n",
    "#### Potential drawbacks:\n",
    "\n",
    "- Harder (than R) to **get started with machine learning**\n",
    "- Less emphasis (than R) on **model interpretability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 How is scikit-learn organized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, software in scikit-learn is organized into six categories:\n",
    "\n",
    "[![scikit-learn homepage](images/6_categories.png)](http://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 What methods should be used for a particular problem? \n",
    "Often the hardest part of solving a machine learning problem can be finding the right estimator for the job, particularly for new practioners. <br>\n",
    "The flowchart below is designed to give users a bit of a rough guide on how to approach problems with regard to which estimators to try on your data. <br>\n",
    "\n",
    "__Task 1:__ Click on this graph to view the chart in a more interactive way on the sklearn website.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![scikit-learn algorithm map](images/02_sklearn_algorithms.png)](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Getting started in scikit-learn with the famous iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What is the famous iris dataset, and how does it relate to machine learning?\n",
    "- How do we load the iris dataset into scikit-learn?\n",
    "- How do we describe a dataset using machine learning terminology?\n",
    "- What are scikit-learn's four key requirements for working with data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Introducing the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Iris](images/03_iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 50 samples of 3 different species of iris (150 samples total)\n",
    "- Measurements: sepal length, sepal width, petal length, petal width\n",
    "- The data in plain text looks like the following:\n",
    "```\n",
    "5.1,3.5,1.4,0.2,Iris-setosa\n",
    "4.9,3.0,1.4,0.2,Iris-setosa\n",
    "4.7,3.2,1.3,0.2,Iris-setosa\n",
    "4.6,3.1,1.5,0.2,Iris-setosa\n",
    "5.0,3.6,1.4,0.2,Iris-setosa\n",
    "5.4,3.9,1.7,0.4,Iris-setosa\n",
    "...\n",
    "6.2,2.9,4.3,1.3,Iris-versicolor\n",
    "5.1,2.5,3.0,1.1,Iris-versicolor\n",
    "5.7,2.8,4.1,1.3,Iris-versicolor\n",
    "...\n",
    "6.3,3.3,6.0,2.5,Iris-virginica\n",
    "5.8,2.7,5.1,1.9,Iris-virginica\n",
    "7.1,3.0,5.9,2.1,Iris-virginica\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Machine learning on the iris dataset\n",
    "\n",
    "- Framed as a **supervised learning** problem: Predict the species of an iris using the measurements\n",
    "- Famous dataset for machine learning because prediction is **easy**\n",
    "- Learn more about the iris dataset: [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loading the scikit-learn iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit includes a number of example datasets, stored in a scikit friendly format. More details on this format, are located [here](http://scikit-learn.org/stable/datasets/index.html).  Below is some code to load sklearn's version of the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save an \"sklearn.datasets.base.Bunch\" object containing iris dataset and its attributes\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 5 rows of iris data\n",
    "pd.DataFrame(iris.data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Machine learning terminology\n",
    "\n",
    "- Each data row is an **observation** (also known as: sample, example, instance, record)\n",
    "- Each data column is a **feature** (also known as: predictor, attribute, independent variable, input, regressor, covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each value we are predicting is the **response** (also known as: target, outcome, label, dependent variable)\n",
    "- **Classification** is supervised learning in which the response is categorical (as is in the iris data set, where the **response** is the iris variety, of which there are only three.)\n",
    "- **Regression** is supervised learning in which the response is ordered and continuous (e.g. prediction of stock prices, cholesterol levels, swimming speed, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print integers representing the species of each observation\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the encoding scheme for species: 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Requirements for working with data in scikit-learn\n",
    "\n",
    "1. Features and response are **separate objects**\n",
    "2. Features and response should be **numeric**\n",
    "3. Features and response should be **NumPy arrays**\n",
    "4. Features and response should have **specific shapes**, i.e., for each row of features there should be a corresponding response row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the types of the features and response\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the features (first dimension = number of observations, second dimensions = number of features)\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the response (single dimension matching the number of observations)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2:__ Store the feature data in the variable X and the target labels in the variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# store response vector in \"y\"\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Test cases\n",
    "assert (150, 4) == X.shape\n",
    "assert (150,) == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Resources\n",
    "\n",
    "- scikit-learn documentation: [Dataset loading utilities](http://scikit-learn.org/stable/datasets/)\n",
    "- Jake VanderPlas: Fast Numerical Computing with NumPy ([slides](https://speakerdeck.com/jakevdp/losing-your-loops-fast-numerical-computing-with-numpy-pycon-2015), [video](https://www.youtube.com/watch?v=EEUXKG97YRw))\n",
    "- Scott Shell: [An Introduction to NumPy](http://www.engr.ucsb.edu/~shell/che210d/numpy.pdf) (PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a machine learning model with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What is the **K-nearest neighbors** classification model?\n",
    "- What are the four steps for **model training and prediction** in scikit-learn?\n",
    "- How can I apply this pattern to **other machine learning models**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 K-nearest neighbors (KNN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the training data that are \"nearest\" to the measurements of the unknown iris.\n",
    "3. Use the most popular response value from the K nearest neighbors as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Example training data \n",
    "**Note:** The data displayed below wil be used to illustrate KNN classicification, it is not from the IRIS data set, we will return to that shortly.\n",
    "\n",
    "Initially there are 60 points in each classã€‚ Each point's color indicates its class. So, for this problem the **features** are (x,y) points and **labels** are point colors. \n",
    "\n",
    "![Training data](images/04_knn_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=1)\n",
    "The figure below shows the 1NN classification map: each pixel is classified by 1NN using all the data.<br>\n",
    "The color of an area designates how points that land in that area are classified.\n",
    "\n",
    "![1NN classification map](images/04_1nn_map.png)\n",
    "\n",
    "The small islands are from isolated training points whose labels differ from points that surround it.  They have this effect when K=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=5)\n",
    "\n",
    "The 5NN classification map is shown below. White areas correspond to the unclassified regions, where 5NN voting is tied (for example, if there are two green, two red and one blue points among 5 nearest neighbors).\n",
    "\n",
    "![5NN classification map](images/04_5nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Image Credits: [Data3classes](http://commons.wikimedia.org/wiki/File:Data3classes.png#/media/File:Data3classes.png), [Map1NN](http://commons.wikimedia.org/wiki/File:Map1NN.png#/media/File:Map1NN.png), [Map5NN](http://commons.wikimedia.org/wiki/File:Map5NN.png#/media/File:Map5NN.png) by Agor153. Licensed under CC BY-SA 3.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Reviewing the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the description of the iris dataset\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 150 **observations**\n",
    "- 4 **features** (sepal length, sepal width, petal length, petal width)\n",
    "- **Response** variable is the iris species\n",
    "- **Classification** problem since response is categorical\n",
    "- More information in the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4  scikit-learn 4-step modeling pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the estimator class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** \"Instantiate\" the \"estimator\"\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for model\n",
    "- \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn) # here you can see the parameters and their current settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\")\n",
    "\n",
    "- Model is learning the relationship between X and y\n",
    "- Occurs *in-place*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X, y)  # Fit tries to determine a relationship between X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Predict the response for a new observation\n",
    "\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict([[3, 5, 4, 2]])  # Predict uses the relationship found by fit and applies it to new X value(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a NumPy array\n",
    "- Can predict for multiple observations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Using a different value for K\n",
    "\n",
    "__Task 3:__ Fit a k-nearest neighbors to the training data (`X`, and `y`) use it to predict the response of `X_new`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model (using the value K=5 instead of K=1)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# fit the model with data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# predict the response for new observations\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Using a different classification model\n",
    "__Task 4:__ We have the first two steps given to you when applying this pattern to another machine learning model -- Logistic Regression (aka logit, MaxEnt) classifier. \n",
    "\n",
    "Please fill in the next two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Note: despite it's name LogisticRegression is used for classification\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# predict the response for new observations\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Resources\n",
    "\n",
    "- [Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html) (user guide), [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (class documentation)\n",
    "- [Logistic Regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) (user guide), [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (class documentation)\n",
    "- [Videos from An Introduction to Statistical Learning](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n",
    "    - Classification Problems and K-Nearest Neighbors (Chapter 2)\n",
    "    - Introduction to Classification (Chapter 4)\n",
    "    - Logistic Regression and Maximum Likelihood (Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing machine learning models in scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you might have the following questions\n",
    "\n",
    "- How do I choose **which model to use** for my supervised learning task?\n",
    "- How do I choose the **best tuning parameters** for that model?\n",
    "- How do I estimate the **likely performance of my model** on out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's review what we've learned so far in this lab\n",
    "\n",
    "- Classification task: Predicting the species of an unknown iris\n",
    "- Used three classification models: KNN (K=1), KNN (K=5), logistic regression\n",
    "- Need a way to choose between the models\n",
    "\n",
    "** So our next topic is:** Model evaluation procedures.  It's a [big topic](http://scikit-learn.org/stable/model_selection.html#model-selection), but we'll start at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Evaluation procedure #1: Train and test on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the model on the **entire dataset**.\n",
    "2. Test the model on the **same dataset**, and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert (X == iris.data).all()  # if these statement fail, rerun your notebook\n",
    "assert (y == iris.target).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response values for the observations in X\n",
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted response values\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "# check how many predictions were generated\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy:\n",
    "\n",
    "- **Proportion** of correct predictions\n",
    "- Common **evaluation metric** for classification problems\n",
    "\n",
    "__Task 5:__ Compute the accuracy of your `logreg` classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here:\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quantity is known as **training accuracy**.\n",
    "\n",
    "Computing accuracy and other machine learning metrics is such a common task sklean has a whole module [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) dedicated to this task. Below is an example of using it to compute the accuracy of `y_pred` versus `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute classification accuracy for the logistic regression model\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the accuracy of both the K=5 and K=1 KNN-Classifiers discussed earlier.\n",
    "\n",
    "####  KNN (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 6:__  Explain why does K=1 has an accuracy of 1.0?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your solution here.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems with training and testing on the same data\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "- But, maximizing training accuracy rewards **overly complex models** that won't necessarily generalize\n",
    "- Unnecessarily complex models **overfit** the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overfitting](images/05_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image Credit: [Overfitting](http://commons.wikimedia.org/wiki/File:Overfitting.svg#/media/File:Overfitting.svg) by Chabacano. Licensed under GFDL via Wikimedia Commons.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluation procedure #2: Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
    "2. Train the model on the **training set**.\n",
    "3. Test the model on the **testing set**, and evaluate how well we did\n",
    "\n",
    "The [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function allows one to randomly select subsets of features and labels for use in model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 1: split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.4, random_state=4)\n",
    "# test_size is the fraction of the data used for test, \n",
    "# (1 - test_size) is used for train.\n",
    "# random_state is the seed used to generate random row selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train/test split](images/05_train_test_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this accomplish?\n",
    "\n",
    "- Model can be trained and tested on **different data**\n",
    "- Response values are known for the testing set, and thus **predictions can be evaluated** out-of-sample\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the orginal shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 7:__ Print the shapes of the 2 new X and 2 new y arrays. Do the dimensions make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of the new X objects\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of the new y objects\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: train the model on the training set\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for KNN with K=5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 8:__ Compute and print the accuracy score of `KNN` with K=5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for KNN with K=1:\n",
    "\n",
    "__Task 9:__ Train the KNN model for K=1 and then print its accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Can we find an even better value for K? **  Below is a computer experiment to try and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try K=1 through K=25 and record testing accuracy\n",
    "import numpy as np\n",
    "k_range = list(range(1, 26))\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Matplotlib (scientific plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "print(list(zip(scores, k_range)))\n",
    "scores = np.array(scores)\n",
    "print('best [score, k] pair = [%g, %g]' % (np.max(scores),k_range[np.argmax(scores)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training accuracy** rises as model complexity increases\n",
    "- **Testing accuracy** penalizes models that are too complex or not complex enough\n",
    "- For KNN models, complexity is determined by the **value of K** (lower value = more complex)\n",
    "\n",
    "__Task 10:__ Explain why lower values of k represent more complex models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your solution here.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Making predictions on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with a good known parameter\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# train the model with X and y (not X_train and y_train)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction for an out-of-sample observation\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Downsides of train/test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provides a **high-variance estimate** of out-of-sample accuracy\n",
    "- In the next lab we will see how **K-fold cross-validation** overcomes this limitation\n",
    "- But, train/test split is still useful because of its **flexibility and speed**\n",
    "\n",
    "__Task 11__:  Demonstrate the variability of measured accuracy\n",
    "Write some code to similar to the previous computer experiment to demonstrate that classifier accuracy depends on train/test splits. Hint:  Changing `random_state` in `train_test_split` will cause a new random selection of train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your solution here.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
    "- Video: [Estimating prediction error](https://www.youtube.com/watch?v=_2ij6eaaSl0&t=2m34s) (12 minutes, starting at 2:34) by Hastie and Tibshirani\n",
    "- [Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "    - [Guiding questions](https://github.com/justmarkham/DAT8/blob/master/homework/09_bias_variance.md) when reading this article\n",
    "- Video: [Visualizing bias and variance](http://work.caltech.edu/library/081.html) (15 minutes) by Abu-Mostafa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
