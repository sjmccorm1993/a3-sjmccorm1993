{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3b\n",
    "\n",
    "## Overview:\n",
    "* [Part 1: Cross validation for parameter tuning, model selection, and feature selection](#Part-1:-Cross-validation-for-parameter-tuning,-model-selection,-and-feature-selection)\n",
    "* [Part 2: Efficiently searching for optimal tuning parameters](#Part-2:-Efficiently-searching-for-optimal-tuning-parameters)\n",
    "* [Part 3: Evaluating a classification model](#Part-3:-Evaluating-a-classification-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Cross-validation for parameter tuning, model selection, and feature selection\n",
    "*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "- How does **K-fold cross-validation** overcome this limitation?\n",
    "- How can cross-validation be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**?\n",
    "- What are some possible **improvements** to cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a way to choose between machine learning models\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- But, it provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973684210526\n",
      "1.0\n",
      "1.0\n",
      "0.947368421053\n",
      "0.973684210526\n"
     ]
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "# this demonstrates that the accuracy depends on which samples are used to train and test\n",
    "for rs in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rs)\n",
    "\n",
    "    # check classification accuracy of KNN with K=5\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "**Answer:** That's the essense of cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]      [0, 1, 2, 3, 4]     \n",
      "    2     [0, 1, 2, 3, 4, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]      [5, 6, 7, 8, 9]     \n",
      "    3     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]   [10, 11, 12, 13, 14]   \n",
      "    4     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24]   [15, 16, 17, 18, 19]   \n",
      "    5     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]   [20, 21, 22, 23, 24]   \n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "splits = kf.split(X[:25])\n",
    "\n",
    "# print the indices of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(splits, start=1):\n",
    "    print('{!r:^9} {} {!r:^25}'.format(iteration, list(data[0]), list(data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset contains **25 observations** (numbered 0 through 24)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is generally recommended\n",
    "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "    - scikit-learn's `cross_val_score` function does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          0.86666667  0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666656, 0.96666666666666656, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.98000000000000009, 0.96666666666666656, 0.96666666666666656, 0.97333333333333338, 0.95999999999999996, 0.96666666666666656, 0.95999999999999996, 0.96666666666666656, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.98000000000000009, 20)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)\n",
    "max(zip(k_scores, k_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118b9df60>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAokxxpiK/F93pGKkN6h/eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111494b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best KNN model with logistic regression on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1:__ Print the mean 10-fold cross validation score of the default logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Select whether the Newspaper feature should be included in the linear regression model on the advertising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the advertising dataset\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Python list of three feature names\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "# use the list to select a subset of the DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select the Sales column as the response (y)\n",
    "y = data.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "lm = LinearRegression()\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.56038438  3.29767522  2.08943356  2.82474283  1.3027754   1.74163618\n",
      "  8.17338214  2.11409746  3.04273109  2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# fix the sign of MSE scores\n",
    "mse_scores = -scores\n",
    "print(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.88689808  1.81595022  1.44548731  1.68069713  1.14139187  1.31971064\n",
      "  2.85891276  1.45399362  1.7443426   1.56614748]\n"
     ]
    }
   ],
   "source": [
    "# convert from MSE to RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.69135317081\n"
     ]
    }
   ],
   "source": [
    "# calculate the average RMSE\n",
    "print(rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2:__ Evaluate the model instead on all features but Newspaper. To do so, Compute the _average root mean squared error (RMSE)_ of the 10-fold cross validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67967484191\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with two features (excluding Newspaper)\n",
    "feature_cols = ['TV', 'radio']\n",
    "X = data[feature_cols]\n",
    "# YOUR CODE HERE\n",
    "print(avg_rmse)\n",
    "assert 1 < avg_rmse < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Efficiently searching for optimal tuning parameters\n",
    "*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- How can K-fold cross-validation be used to search for an **optimal tuning parameter**?\n",
    "- How can this process be made **more efficient**?\n",
    "- How do you search for **multiple tuning parameters** at once?\n",
    "- What do you do with those tuning parameters before making **real predictions**?\n",
    "- How can the **computational expense** of this process be reduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for cross-validation:\n",
    "\n",
    "- Dataset is split into K \"folds\" of **equal size**\n",
    "- Each fold acts as the **testing set** 1 time, and acts as the **training set** K-1 times\n",
    "- **Average testing performance** is used as the estimate of out-of-sample performance\n",
    "\n",
    "Benefits of cross-validation:\n",
    "\n",
    "- More **reliable** estimate of out-of-sample performance than train/test split\n",
    "- Can be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**\n",
    "\n",
    "Drawbacks of cross-validation:\n",
    "\n",
    "- Can be computationally **expensive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of parameter tuning using `cross_val_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3: __ Instantiate a KNN model with K=5 and print the 10-fold cross val scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          0.86666667  0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "# YOUR CODE HERE\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666656, 0.96666666666666656, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.98000000000000009, 0.96666666666666656, 0.96666666666666656, 0.97333333333333338, 0.95999999999999996, 0.96666666666666656, 0.95999999999999996, 0.96666666666666656, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118b9de48>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAokxxpiK/F93pGKkN6h/eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11898a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More efficient parameter tuning using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows you to define a **grid of parameters** that will be **searched** using K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "print(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can set **`n_jobs = -1`** to run computations in parallel (if supported by your computer and OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=30, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the grid with data\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukezhu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.96000, std: 0.05333, params: {'n_neighbors': 1},\n",
       " mean: 0.95333, std: 0.05207, params: {'n_neighbors': 2},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 3},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 4},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 5},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 6},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 7},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 8},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 9},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 10},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 11},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 12},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 13},\n",
       " mean: 0.97333, std: 0.04422, params: {'n_neighbors': 14},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 15},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 16},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 17},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 18},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 19},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 20},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 21},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 22},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 23},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 24},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 25},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 26},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 27},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 28},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 29},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 30}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "# Ignore the deprecation warning, it's just a warning\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "[ 1.          0.93333333  1.          0.93333333  0.86666667  1.\n",
      "  0.86666667  1.          1.          1.        ]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukezhu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/lukezhu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/lukezhu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# examine the first tuple\n",
    "print(grid.grid_scores_[0].parameters)\n",
    "print(grid.grid_scores_[0].cv_validation_scores)\n",
    "print(grid.grid_scores_[0].mean_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4:__ Now that you've seen how to access the values in each tuple, create a 1-D list of all mean validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666667, 0.96666666666666667, 0.96666666666666667, 0.96666666666666667, 0.96666666666666667, 0.96666666666666667, 0.97333333333333338, 0.96666666666666667, 0.96666666666666667, 0.97333333333333338, 0.97999999999999998, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97999999999999998, 0.97333333333333338, 0.97999999999999998, 0.96666666666666667, 0.96666666666666667, 0.97333333333333338, 0.95999999999999996, 0.96666666666666667, 0.95999999999999996, 0.96666666666666667, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukezhu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert len(grid_mean_scores) == 30\n",
    "assert isinstance(grid_mean_scores[0], np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.plot(k_range, grid_mean_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching multiple parameters simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example:** tuning `max_depth` and `min_samples_leaf` for a `DecisionTreeClassifier`\n",
    "- Could tune parameters **independently**: change `max_depth` while leaving `min_samples_leaf` at its default value, and vice versa\n",
    "- But, best performance might be achieved when **neither parameter** is at its default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the complete results\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the best parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your model using all data and the best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=13, weights='uniform')\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction on out-of-sample data\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut: GridSearchCV automatically refits the best model using all of the data\n",
    "grid.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing computational expense using `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Searching many different parameters at once may be computationally infeasible\n",
    "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Important:** Specify a continuous distribution (rather than a list of values) for any continous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "rand.fit(X, y)\n",
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)\n",
    "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html)\n",
    "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
    "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Evaluating a classification model\n",
    "\n",
    "*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by **changing the classification threshold**?\n",
    "- What is the purpose of an **ROC curve**?\n",
    "- How does **Area Under the Curve (AUC)** differ from classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](images/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted responses\n",
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities for class 1\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted classes with the lower threshold\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity has increased (used to be 0.24)\n",
    "print(46 / float(46 + 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity has decreased (used to be 0.91)\n",
    "print(80 / float(80 + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be **adjusted** to increase sensitivity or specificity\n",
    "- Sensitivity and specificity have an **inverse relationship**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC is useful as a **single number summary** of classifier performance.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a **variety of metrics**\n",
    "- Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to **set a classification threshold**\n",
    "- Still useful when there is **high class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Resources\n",
    "\n",
    "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by me\n",
    "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
    "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
    "- Graphic: How [classification threshold](https://media.amazonwebservices.com/blog/2015/ml_adjust_model_1.png) affects different evaluation metrics (from a [blog post](https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/) about Amazon Machine Learning)\n",
    "\n",
    "\n",
    "## ROC and AUC Resources\n",
    "\n",
    "- Lesson notes: [ROC Curves](http://ebp.uga.edu/courses/Chapter%204%20-%20Diagnosis%20I/8%20-%20ROC%20curves.html) (from the University of Georgia)\n",
    "- Video: [ROC Curves and Area Under the Curve](https://www.youtube.com/watch?v=OAl6eAyP-yo) (14 minutes) by me, including [transcript and screenshots](http://www.dataschool.io/roc-curves-and-auc-explained/) and a [visualization](http://www.navan.name/roc/)\n",
    "- Video: [ROC Curves](https://www.youtube.com/watch?v=21Igj5Pr6u4) (12 minutes) by Rahul Patwari\n",
    "- Paper: [An introduction to ROC analysis](http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf) by Tom Fawcett\n",
    "- Usage examples: [Comparing different feature sets](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf) for detecting fraudulent Skype users, and [comparing different classifiers](http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Bradley_PR97.pdf) on a number of popular datasets\n",
    "\n",
    "## Other Resources\n",
    "\n",
    "- scikit-learn documentation: [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Guide: [Comparing model evaluation procedures and metrics](https://github.com/justmarkham/DAT8/blob/master/other/model_evaluation_comparison.md) by me\n",
    "- Video: [Counterfactual evaluation of machine learning models](https://www.youtube.com/watch?v=QWCSxAKR-h0) (45 minutes) about how Stripe evaluates its fraud detection model, including [slides](http://www.slideshare.net/MichaelManapat/counterfactual-evaluation-of-machine-learning-models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
