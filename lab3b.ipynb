{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3b\n",
    "\n",
    "## Contents\n",
    "* [Part 1: Cross validation for parameter tuning, model selection, and feature selection](#Part-1:-Cross-validation-for-parameter-tuning,-model-selection,-and-feature-selection)\n",
    "* [Part 2: Efficiently searching for optimal tuning parameters](#Part-2:-Efficiently-searching-for-optimal-tuning-parameters)\n",
    "* [Part 3: Evaluating a classification model](#Part-3:-Evaluating-a-classification-model)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cross-validation for parameter tuning, model selection, and feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "- How does **K-fold cross-validation** overcome this limitation?\n",
    "- How can cross-validation be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**?\n",
    "- What are some possible **improvements** to cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a principled way to choose between machine learning approaches (models, model parameters, features)\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- But, it provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we train and test the KNN (k=5) model using 100 different train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best [k, score] = [2, 1], mean score =  0.96049382716\n"
     ]
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "# this demonstrates that the accuracy depends on which samples are used to train and test\n",
    "import numpy as np\n",
    "scores = []\n",
    "for rs in range(1,100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=rs)\n",
    "\n",
    "    # check classification accuracy of KNN with K=5\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "scores = np.array(scores)    \n",
    "i = np.argmax(scores)\n",
    "print('best [k, score] = [%g, %g], mean score = '%(i+1, scores[i]), scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1:__ Plot a histogram of the measured accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.,   0.,  14.,   0.,   0.,  36.,   0.,  30.,   0.,  11.]),\n",
       " array([ 0.91111111,  0.92      ,  0.92888889,  0.93777778,  0.94666667,\n",
       "         0.95555556,  0.96444444,  0.97333333,  0.98222222,  0.99111111,  1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA12SGmGgS1Ij/g8DztnA1PdrLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a85f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above clearly shows that test accuracy depends on the train/test split used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging the results of a number of train/test splits provides a better estimate of a models out-of-sample performance.  K-fold cross-validation provides a recipe for doing this.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)\n",
    "\n",
    "`sklean` provides a variety of tools for doing k-fold cross-validation.  Below is an example of `model_selection.Kfold`.  Given the number of splits (i.e. folds) and a feature matrix, this function returns a list of train and test row indices to use with each run of training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]         [0, 1, 2]        \n",
      "    2     [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14]         [3, 4, 5]        \n",
      "    3     [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14]         [6, 7, 8]        \n",
      "    4     [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14]        [9, 10, 11]       \n",
      "    5     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]       [12, 13, 14]       \n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 15 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "splits = kf.split(X[:15])\n",
    "\n",
    "# print the indices of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(splits, start=1):\n",
    "    print('{!r:^9} {} {!r:^25}'.format(iteration, list(data[0]), list(data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Kfold` example above,\n",
    "- The feature dataset contains **15 observations** (i.e. rows, numbered 0 through 14)\n",
    "- `n_splits=5` corresponds to 5-fold cross-validation\n",
    "- five different sets of train/test indices are produced, appropriate for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    " - However order of rows and the value of k affects outcome, i.e. still setup dependent\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is often recommended (YMMV)\n",
    "2. For classification problems, [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling) is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "    - scikit-learn's `cross_val_score` function, which we discuss below, does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset using cross-validation\n",
    "\n",
    "The code below finds mean accuracy for a set of parameters using cross-validation using `model_selection.cross_val_score` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          0.86666667  0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best [k, score] = [13, 0.98]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "i = np.argmax(np.array(k_scores))\n",
    "print('best [k, score] = [%g, %g]'%(k_range[i], k_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119f7a710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAokxxpiK/F93pGKkN6h/eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115bd09b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best KNN model with Logistic Regression classifier on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2:__ Print the mean 10-fold cross validation score of the default Logistic Regression classifier model applied to the iris dataset.  Include a comment as to which model you would select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Cross-validation Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Steps for cross-validation: **\n",
    "- Dataset is split into K \"folds\" of **equal size**\n",
    "- Each fold acts as the **testing set** 1 time, and acts as the **training set** K-1 times\n",
    "- **Average testing performance** is used as the estimate of out-of-sample performance\n",
    "\n",
    "** Benefits of cross-validation: **\n",
    "- More **reliable** estimate of out-of-sample performance than train/test split\n",
    "- Can be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**\n",
    "\n",
    "** Drawbacks of cross-validation: **\n",
    "\n",
    "- Can be computationally **expensive**\n",
    "\n",
    "### 1.8 Cross-validation Improvements\n",
    "\n",
    "**Repeated cross-validation**\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More honest estimate of out-of-sample performance since hold-out set is **truly out-of-sample**, but unless the hold-out set is large enough may not be accurate.\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 2: Efficiently searching for hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- How can K-fold cross-validation be used to search for **good classifier parameters**?\n",
    "- How can this process be made **more efficient**?\n",
    "- How do you search for **multiple tuning parameters** at once?\n",
    "- What do you do with those tuning parameters before making **real predictions**?\n",
    "- How can the **computational expense** of this process be reduced?\n",
    "\n",
    "Searching for better sets of parameters using cross validation is such a common task that [sklearn.model_selection](http://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers) provides a number of functions for automating this task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) function allows you to define a **grid of parameters** that will exhaustively be **searched** using K-fold cross-validation in order to find the best set of parameters.  Below is an example with a single set of **grid parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can set **`n_jobs = -1`** to run computations in parallel (if supported by your computer and OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the grid search on the data\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00041754,  0.00034301,  0.00032818,  0.00065224,  0.00037169,\n",
       "         0.00033414,  0.00028858,  0.00027833,  0.00028088,  0.00028057,\n",
       "         0.00027852,  0.00027752,  0.00027785,  0.00031524,  0.00029161,\n",
       "         0.00028808,  0.00027697,  0.0002768 ,  0.00027573,  0.00027609,\n",
       "         0.00028012,  0.00028164,  0.00028176,  0.00028207,  0.00029092,\n",
       "         0.00028281,  0.00028226,  0.0002835 ,  0.00029168,  0.0002923 ]),\n",
       " 'mean_score_time': array([ 0.0006578 ,  0.00064616,  0.00059409,  0.00109591,  0.00060136,\n",
       "         0.00054569,  0.00049553,  0.00048804,  0.00049436,  0.0004941 ,\n",
       "         0.00049782,  0.00049317,  0.00049863,  0.00053949,  0.00051432,\n",
       "         0.00050416,  0.00049858,  0.00050147,  0.00050132,  0.00050058,\n",
       "         0.00051172,  0.00050905,  0.0005192 ,  0.00051994,  0.0005388 ,\n",
       "         0.0005192 ,  0.00052011,  0.00053413,  0.00053144,  0.00055201]),\n",
       " 'mean_test_score': array([ 0.96      ,  0.95333333,  0.96666667,  0.96666667,  0.96666667,\n",
       "         0.96666667,  0.96666667,  0.96666667,  0.97333333,  0.96666667,\n",
       "         0.96666667,  0.97333333,  0.98      ,  0.97333333,  0.97333333,\n",
       "         0.97333333,  0.97333333,  0.98      ,  0.97333333,  0.98      ,\n",
       "         0.96666667,  0.96666667,  0.97333333,  0.96      ,  0.96666667,\n",
       "         0.96      ,  0.96666667,  0.95333333,  0.95333333,  0.95333333]),\n",
       " 'mean_train_score': array([ 1.        ,  0.97851852,  0.96074074,  0.9637037 ,  0.96888889,\n",
       "         0.97259259,  0.97333333,  0.97925926,  0.97925926,  0.9762963 ,\n",
       "         0.98      ,  0.97851852,  0.98      ,  0.97925926,  0.97925926,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97407407,\n",
       "         0.97555556,  0.97111111,  0.97333333,  0.97037037,  0.96962963,\n",
       "         0.96      ,  0.96148148,  0.95481481,  0.95925926,  0.95259259]),\n",
       " 'param_n_neighbors': masked_array(data = [1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
       "  29 30],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 12},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 14},\n",
       "  {'n_neighbors': 15},\n",
       "  {'n_neighbors': 16},\n",
       "  {'n_neighbors': 17},\n",
       "  {'n_neighbors': 18},\n",
       "  {'n_neighbors': 19},\n",
       "  {'n_neighbors': 20},\n",
       "  {'n_neighbors': 21},\n",
       "  {'n_neighbors': 22},\n",
       "  {'n_neighbors': 23},\n",
       "  {'n_neighbors': 24},\n",
       "  {'n_neighbors': 25},\n",
       "  {'n_neighbors': 26},\n",
       "  {'n_neighbors': 27},\n",
       "  {'n_neighbors': 28},\n",
       "  {'n_neighbors': 29},\n",
       "  {'n_neighbors': 30}),\n",
       " 'rank_test_score': array([24, 27, 12, 12, 12, 12, 12, 12,  4, 12, 12,  4,  1,  4,  4,  4,  4,\n",
       "         1,  4,  1, 12, 12,  4, 24, 12, 24, 12, 27, 27, 27], dtype=int32),\n",
       " 'split0_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split0_train_score': array([ 1.        ,  0.97037037,  0.95555556,  0.95555556,  0.96296296,\n",
       "         0.97037037,  0.96296296,  0.97037037,  0.97037037,  0.97037037,\n",
       "         0.97037037,  0.97037037,  0.97777778,  0.97037037,  0.97777778,\n",
       "         0.97037037,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97037037,  0.97777778,\n",
       "         0.96296296,  0.96296296,  0.94814815,  0.95555556,  0.94814815]),\n",
       " 'split1_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split1_train_score': array([ 1.        ,  0.98518519,  0.96296296,  0.96296296,  0.97037037,\n",
       "         0.97037037,  0.97777778,  0.98518519,  0.98518519,  0.98518519,\n",
       "         0.98518519,  0.99259259,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.98518519,  0.98518519,  0.98518519,  0.98518519,  0.98518519,\n",
       "         0.98518519,  0.98518519,  0.97037037,  0.97777778,  0.97777778,\n",
       "         0.98518519,  0.97777778,  0.97777778,  0.97777778,  0.95555556]),\n",
       " 'split2_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.]),\n",
       " 'split2_train_score': array([ 1.        ,  0.97777778,  0.95555556,  0.95555556,  0.96296296,\n",
       "         0.97037037,  0.97037037,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.98518519,  0.98518519,  0.97777778,  0.98518519,  0.97777778,\n",
       "         0.98518519,  0.97777778,  0.97777778,  0.97777778,  0.96296296,\n",
       "         0.97037037,  0.95555556,  0.96296296,  0.94814815,  0.94814815,\n",
       "         0.93333333,  0.94074074,  0.94814815,  0.95555556,  0.94814815]),\n",
       " 'split3_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split3_train_score': array([ 1.        ,  0.98518519,  0.96296296,  0.96296296,  0.97037037,\n",
       "         0.97777778,  0.97037037,  0.98518519,  0.98518519,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.98518519,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97037037,\n",
       "         0.96296296,  0.97037037,  0.96296296,  0.97037037,  0.94814815]),\n",
       " 'split4_test_score': array([ 0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667,\n",
       "         0.86666667,  0.86666667,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split4_train_score': array([ 1.        ,  0.97777778,  0.97777778,  0.97777778,  0.98518519,\n",
       "         0.98518519,  0.98518519,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.98518519,  0.97777778,  0.98518519,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97037037,  0.97777778,  0.97037037,  0.97037037,\n",
       "         0.95555556,  0.94814815,  0.94814815,  0.94814815,  0.94814815]),\n",
       " 'split5_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.86666667,  0.93333333,  0.86666667,\n",
       "         0.86666667,  0.93333333,  0.93333333,  0.86666667,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.86666667,  0.93333333,\n",
       "         0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667]),\n",
       " 'split5_train_score': array([ 1.        ,  0.97037037,  0.95555556,  0.96296296,  0.96296296,\n",
       "         0.95555556,  0.97037037,  0.97037037,  0.97777778,  0.97037037,\n",
       "         0.98518519,  0.97777778,  0.98518519,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.98518519,  0.98518519,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.96296296,  0.97037037,  0.96296296,  0.96296296,  0.96296296]),\n",
       " 'split6_test_score': array([ 0.86666667,  0.86666667,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split6_train_score': array([ 1.        ,  0.98518519,  0.97037037,  0.97037037,  0.97777778,\n",
       "         0.98518519,  0.97777778,  0.99259259,  0.99259259,  0.98518519,\n",
       "         0.99259259,  0.98518519,  0.99259259,  0.99259259,  0.98518519,\n",
       "         0.98518519,  0.97777778,  0.98518519,  0.98518519,  0.98518519,\n",
       "         0.98518519,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.96296296,  0.97037037,  0.95555556,  0.96296296,  0.96296296]),\n",
       " 'split7_test_score': array([ 1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  0.93333333,\n",
       "         0.93333333,  1.        ,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split7_train_score': array([ 1.        ,  0.97777778,  0.95555556,  0.96296296,  0.96296296,\n",
       "         0.97037037,  0.97037037,  0.97777778,  0.97037037,  0.97777778,\n",
       "         0.97777778,  0.97037037,  0.97037037,  0.97777778,  0.97777778,\n",
       "         0.97037037,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97037037,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97037037,  0.97037037,  0.96296296,  0.96296296,  0.95555556]),\n",
       " 'split8_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.]),\n",
       " 'split8_train_score': array([ 1.        ,  0.97777778,  0.95555556,  0.95555556,  0.96296296,\n",
       "         0.97037037,  0.97037037,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.98518519,  0.97777778,  0.98518519,  0.98518519,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97037037,  0.97777778,  0.97037037,  0.97037037,\n",
       "         0.96296296,  0.97037037,  0.94814815,  0.95555556,  0.95555556]),\n",
       " 'split9_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.]),\n",
       " 'split9_train_score': array([ 1.        ,  0.97777778,  0.95555556,  0.97037037,  0.97037037,\n",
       "         0.97037037,  0.97777778,  0.97777778,  0.97777778,  0.96296296,\n",
       "         0.96296296,  0.96296296,  0.97777778,  0.97037037,  0.97777778,\n",
       "         0.96296296,  0.96296296,  0.95555556,  0.96296296,  0.94074074,\n",
       "         0.94814815,  0.94814815,  0.95555556,  0.95555556,  0.94814815,\n",
       "         0.94074074,  0.93333333,  0.93333333,  0.94074074,  0.94074074]),\n",
       " 'std_fit_time': array([  1.54363392e-04,   1.57407008e-05,   2.67565244e-05,\n",
       "          2.13400160e-04,   1.22736717e-04,   8.58077211e-05,\n",
       "          1.83210988e-05,   2.36791783e-06,   8.59263338e-06,\n",
       "          4.20834119e-06,   2.46575994e-06,   1.01152436e-06,\n",
       "          1.16898066e-06,   7.55796523e-05,   1.25998975e-05,\n",
       "          2.57386190e-05,   2.33126560e-06,   1.58148994e-06,\n",
       "          1.37478859e-06,   1.34024327e-06,   5.59593344e-06,\n",
       "          1.05509582e-05,   2.84268542e-06,   4.01712312e-06,\n",
       "          9.74884212e-06,   2.30860108e-06,   1.62911609e-06,\n",
       "          4.48131805e-06,   1.90042790e-05,   3.26206806e-06]),\n",
       " 'std_score_time': array([  2.20541567e-04,   8.86223891e-05,   1.40422746e-04,\n",
       "          3.08142048e-04,   1.99742983e-04,   1.00470947e-04,\n",
       "          1.76781227e-05,   7.17319056e-06,   1.36275563e-05,\n",
       "          4.56893611e-06,   1.35046816e-05,   2.21421428e-06,\n",
       "          7.56895444e-06,   5.31653973e-05,   1.39281351e-05,\n",
       "          1.51905381e-05,   5.79489587e-06,   4.30086235e-06,\n",
       "          4.43746873e-06,   2.67241598e-06,   1.07129562e-05,\n",
       "          1.21469294e-05,   1.30922196e-05,   9.08797083e-06,\n",
       "          3.41863395e-05,   3.06449037e-06,   2.05718072e-06,\n",
       "          3.36997809e-05,   1.15223040e-05,   9.53259974e-06]),\n",
       " 'std_test_score': array([ 0.05333333,  0.05206833,  0.04472136,  0.04472136,  0.04472136,\n",
       "         0.04472136,  0.04472136,  0.04472136,  0.03265986,  0.04472136,\n",
       "         0.04472136,  0.03265986,  0.0305505 ,  0.04422166,  0.03265986,\n",
       "         0.03265986,  0.03265986,  0.0305505 ,  0.03265986,  0.0305505 ,\n",
       "         0.03333333,  0.03333333,  0.03265986,  0.04422166,  0.03333333,\n",
       "         0.04422166,  0.04472136,  0.04268749,  0.04268749,  0.04268749]),\n",
       " 'std_train_score': array([ 0.        ,  0.00518519,  0.00744435,  0.00698813,  0.00725775,\n",
       "         0.00814815,  0.00592593,  0.00645763,  0.00645763,  0.00645763,\n",
       "         0.00814815,  0.0084132 ,  0.00578537,  0.00645763,  0.00296296,\n",
       "         0.00740741,  0.00573775,  0.00811441,  0.00573775,  0.01250514,\n",
       "         0.00996565,  0.01070876,  0.0075541 ,  0.00993808,  0.01120944,\n",
       "         0.01373869,  0.0143635 ,  0.01168869,  0.01007516,  0.006789  ])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A complete record the cross validation search results is stored in\n",
    "# dictionary.  Here it is\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# examine the first run\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3:__ Now that you've seen how to access some the values in cv_results, use them to create a plot of mean test scores and also determine the best set of parameters and its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k:  12\n",
      "Score:  0.98\n",
      "Value of k:  17\n",
      "Score:  0.98\n",
      "Value of k:  19\n",
      "Score:  0.98\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKKWUAuC/AYdVS2MIsO7FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a96a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement your solution using array of of the mean test scores, \n",
    "# called grid_mean_scores\n",
    "\n",
    "grid_mean_scores = grid.cv_results_['mean_test_score']\n",
    "\n",
    "plt.plot(grid_mean_scores)\n",
    "\n",
    "max_score = max(grid_mean_scores)\n",
    "\n",
    "for idx, score in enumerate(grid_mean_scores):\n",
    "    \n",
    "    if score == max_score:\n",
    "        print(\"Value of k: \", idx)\n",
    "        print(\"Score: \", score)\n",
    "\n",
    "# test cases, do not change!\n",
    "assert len(grid_mean_scores)==30\n",
    "assert isinstance(grid_mean_scores[0], np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13}\n",
      "0.98\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Finding the set of parameter and associated model is such a common task, \n",
    "# it is also stored automatically\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Searching multiple parameters simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example:** tuning `max_depth` and `min_samples_leaf` for a `DecisionTreeClassifier`\n",
    "- Could tune parameters **independently**: change `max_depth` while leaving `min_samples_leaf` at its default value, and vice versa\n",
    "- But, best performance might be achieved when **neither parameter** is at its default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00039551,  0.00037632,  0.00034192,  0.00062742,  0.0003721 ,\n",
       "         0.00030832,  0.00028064,  0.00028882,  0.00027976,  0.00029042,\n",
       "         0.00032649,  0.00028231,  0.00027843,  0.0002857 ,  0.0003093 ,\n",
       "         0.00033607,  0.00027955,  0.00028105,  0.00027902,  0.00028434,\n",
       "         0.00028274,  0.00028384,  0.00028026,  0.0002795 ,  0.00027974,\n",
       "         0.00028381,  0.00028214,  0.00028324,  0.00028038,  0.0002804 ,\n",
       "         0.00028217,  0.00028226,  0.00028524,  0.00029233,  0.00029371,\n",
       "         0.00028236,  0.00028334,  0.00028305,  0.00028391,  0.00029297,\n",
       "         0.00039508,  0.00040758,  0.0003787 ,  0.0003778 ,  0.00036666,\n",
       "         0.00035651,  0.00028694,  0.00035415,  0.00031667,  0.00032063,\n",
       "         0.00028551,  0.00028806,  0.0002852 ,  0.0002866 ,  0.00030935,\n",
       "         0.00028701,  0.00028217,  0.00028305,  0.00028317,  0.00028627]),\n",
       " 'mean_score_time': array([ 0.00063286,  0.00061998,  0.00057681,  0.00116179,  0.0006464 ,\n",
       "         0.00050688,  0.00048435,  0.00050614,  0.00048506,  0.00052986,\n",
       "         0.00055599,  0.00052075,  0.00048633,  0.00051844,  0.00053754,\n",
       "         0.00066097,  0.00049512,  0.00051842,  0.00049469,  0.00053582,\n",
       "         0.00050585,  0.00052631,  0.0004998 ,  0.00052493,  0.00050108,\n",
       "         0.00052726,  0.000506  ,  0.00053272,  0.00050814,  0.00052941,\n",
       "         0.00050738,  0.00053239,  0.00052054,  0.00055873,  0.00053205,\n",
       "         0.00053806,  0.00051148,  0.00054173,  0.00051317,  0.00055416,\n",
       "         0.00075243,  0.00082846,  0.00064483,  0.00079019,  0.0007232 ,\n",
       "         0.0007035 ,  0.00058577,  0.0006422 ,  0.00062232,  0.0006212 ,\n",
       "         0.00053353,  0.00056355,  0.00054512,  0.0005533 ,  0.00057518,\n",
       "         0.00056245,  0.00054109,  0.00055509,  0.00053058,  0.00056062]),\n",
       " 'mean_test_score': array([ 0.96      ,  0.96      ,  0.95333333,  0.96      ,  0.96666667,\n",
       "         0.96666667,  0.96666667,  0.96666667,  0.96666667,  0.96666667,\n",
       "         0.96666667,  0.96666667,  0.96666667,  0.96666667,  0.96666667,\n",
       "         0.96666667,  0.97333333,  0.97333333,  0.96666667,  0.97333333,\n",
       "         0.96666667,  0.97333333,  0.97333333,  0.97333333,  0.98      ,\n",
       "         0.97333333,  0.97333333,  0.97333333,  0.97333333,  0.98      ,\n",
       "         0.97333333,  0.97333333,  0.97333333,  0.98      ,  0.98      ,\n",
       "         0.97333333,  0.97333333,  0.98      ,  0.98      ,  0.96666667,\n",
       "         0.96666667,  0.96666667,  0.96666667,  0.96666667,  0.97333333,\n",
       "         0.97333333,  0.96      ,  0.97333333,  0.96666667,  0.97333333,\n",
       "         0.96      ,  0.96666667,  0.96666667,  0.98      ,  0.95333333,\n",
       "         0.97333333,  0.95333333,  0.97333333,  0.95333333,  0.96666667]),\n",
       " 'mean_train_score': array([ 1.        ,  1.        ,  0.97851852,  1.        ,  0.96074074,\n",
       "         1.        ,  0.9637037 ,  1.        ,  0.96888889,  1.        ,\n",
       "         0.97259259,  1.        ,  0.97333333,  1.        ,  0.97925926,\n",
       "         1.        ,  0.97925926,  1.        ,  0.9762963 ,  1.        ,\n",
       "         0.98      ,  1.        ,  0.97851852,  1.        ,  0.98      ,\n",
       "         1.        ,  0.97925926,  1.        ,  0.97925926,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97407407,  1.        ,\n",
       "         0.97555556,  1.        ,  0.97111111,  1.        ,  0.97333333,\n",
       "         1.        ,  0.97037037,  1.        ,  0.96962963,  1.        ,\n",
       "         0.96      ,  1.        ,  0.96148148,  1.        ,  0.95481481,\n",
       "         1.        ,  0.95925926,  1.        ,  0.95259259,  1.        ]),\n",
       " 'param_n_neighbors': masked_array(data = [1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10 11 11 12 12 13 13 14 14 15 15 16\n",
       "  16 17 17 18 18 19 19 20 20 21 21 22 22 23 23 24 24 25 25 26 26 27 27 28 28\n",
       "  29 29 30 30],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_weights': masked_array(data = ['uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 10, 'weights': 'distance'},\n",
       "  {'n_neighbors': 11, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 11, 'weights': 'distance'},\n",
       "  {'n_neighbors': 12, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 12, 'weights': 'distance'},\n",
       "  {'n_neighbors': 13, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 13, 'weights': 'distance'},\n",
       "  {'n_neighbors': 14, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 14, 'weights': 'distance'},\n",
       "  {'n_neighbors': 15, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 15, 'weights': 'distance'},\n",
       "  {'n_neighbors': 16, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 16, 'weights': 'distance'},\n",
       "  {'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 17, 'weights': 'distance'},\n",
       "  {'n_neighbors': 18, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 18, 'weights': 'distance'},\n",
       "  {'n_neighbors': 19, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 19, 'weights': 'distance'},\n",
       "  {'n_neighbors': 20, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 20, 'weights': 'distance'},\n",
       "  {'n_neighbors': 21, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 21, 'weights': 'distance'},\n",
       "  {'n_neighbors': 22, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 22, 'weights': 'distance'},\n",
       "  {'n_neighbors': 23, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 23, 'weights': 'distance'},\n",
       "  {'n_neighbors': 24, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 24, 'weights': 'distance'},\n",
       "  {'n_neighbors': 25, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 25, 'weights': 'distance'},\n",
       "  {'n_neighbors': 26, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 26, 'weights': 'distance'},\n",
       "  {'n_neighbors': 27, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 27, 'weights': 'distance'},\n",
       "  {'n_neighbors': 28, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 28, 'weights': 'distance'},\n",
       "  {'n_neighbors': 29, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 29, 'weights': 'distance'},\n",
       "  {'n_neighbors': 30, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 30, 'weights': 'distance'}),\n",
       " 'rank_test_score': array([52, 52, 57, 52, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,  8,\n",
       "         8, 29,  8, 29,  8,  8,  8,  1,  8,  8,  8,  8,  1,  8,  8,  8,  1,\n",
       "         1,  8,  8,  1,  1, 29, 29, 29, 29, 29,  8,  8, 52,  8, 29,  8, 52,\n",
       "        29, 29,  1, 57,  8, 57,  8, 57, 29], dtype=int32),\n",
       " 'split0_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.93333333,  1.        ,\n",
       "         1.        ,  1.        ,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  0.93333333,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ,\n",
       "         0.93333333,  1.        ,  0.93333333,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ]),\n",
       " 'split0_train_score': array([ 1.        ,  1.        ,  0.97037037,  1.        ,  0.95555556,\n",
       "         1.        ,  0.95555556,  1.        ,  0.96296296,  1.        ,\n",
       "         0.97037037,  1.        ,  0.96296296,  1.        ,  0.97037037,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97037037,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97777778,  1.        ,\n",
       "         0.96296296,  1.        ,  0.96296296,  1.        ,  0.94814815,\n",
       "         1.        ,  0.95555556,  1.        ,  0.94814815,  1.        ]),\n",
       " 'split1_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split1_train_score': array([ 1.        ,  1.        ,  0.98518519,  1.        ,  0.96296296,\n",
       "         1.        ,  0.96296296,  1.        ,  0.97037037,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97777778,  1.        ,  0.98518519,\n",
       "         1.        ,  0.98518519,  1.        ,  0.98518519,  1.        ,\n",
       "         0.98518519,  1.        ,  0.99259259,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.98518519,  1.        ,  0.98518519,\n",
       "         1.        ,  0.98518519,  1.        ,  0.98518519,  1.        ,\n",
       "         0.98518519,  1.        ,  0.98518519,  1.        ,  0.97037037,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.95555556,  1.        ]),\n",
       " 'split2_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split2_train_score': array([ 1.        ,  1.        ,  0.97777778,  1.        ,  0.95555556,\n",
       "         1.        ,  0.95555556,  1.        ,  0.96296296,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.98518519,  1.        ,  0.97777778,\n",
       "         1.        ,  0.98518519,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.96296296,  1.        ,\n",
       "         0.97037037,  1.        ,  0.95555556,  1.        ,  0.96296296,\n",
       "         1.        ,  0.94814815,  1.        ,  0.94814815,  1.        ,\n",
       "         0.93333333,  1.        ,  0.94074074,  1.        ,  0.94814815,\n",
       "         1.        ,  0.95555556,  1.        ,  0.94814815,  1.        ]),\n",
       " 'split3_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split3_train_score': array([ 1.        ,  1.        ,  0.98518519,  1.        ,  0.96296296,\n",
       "         1.        ,  0.96296296,  1.        ,  0.97037037,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97037037,  1.        ,  0.98518519,\n",
       "         1.        ,  0.98518519,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97037037,  1.        ,\n",
       "         0.96296296,  1.        ,  0.97037037,  1.        ,  0.96296296,\n",
       "         1.        ,  0.97037037,  1.        ,  0.94814815,  1.        ]),\n",
       " 'split4_test_score': array([ 0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667,\n",
       "         0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667,\n",
       "         0.86666667,  0.86666667,  0.86666667,  0.86666667,  1.        ,\n",
       "         0.86666667,  1.        ,  0.93333333,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.86666667,  1.        ,\n",
       "         0.93333333,  1.        ,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  0.86666667,\n",
       "         0.93333333,  0.86666667,  1.        ,  0.86666667,  1.        ,\n",
       "         0.93333333,  1.        ,  0.93333333,  1.        ,  0.93333333,\n",
       "         1.        ,  0.86666667,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  0.93333333]),\n",
       " 'split4_train_score': array([ 1.        ,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.98518519,  1.        ,\n",
       "         0.98518519,  1.        ,  0.98518519,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.98518519,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97037037,  1.        ,\n",
       "         0.95555556,  1.        ,  0.94814815,  1.        ,  0.94814815,\n",
       "         1.        ,  0.94814815,  1.        ,  0.94814815,  1.        ]),\n",
       " 'split5_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.86666667,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.86666667,  0.93333333,\n",
       "         0.86666667,  0.93333333,  0.93333333,  1.        ,  0.93333333,\n",
       "         0.93333333,  0.86666667,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.86666667,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.86666667,  0.93333333,  0.86666667,  0.93333333,  0.86666667,\n",
       "         0.93333333,  0.86666667,  0.93333333,  0.86666667,  0.93333333]),\n",
       " 'split5_train_score': array([ 1.        ,  1.        ,  0.97037037,  1.        ,  0.95555556,\n",
       "         1.        ,  0.96296296,  1.        ,  0.96296296,  1.        ,\n",
       "         0.95555556,  1.        ,  0.97037037,  1.        ,  0.97037037,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97037037,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.98518519,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.98518519,  1.        ,  0.98518519,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.96296296,  1.        ,  0.97037037,  1.        ,  0.96296296,\n",
       "         1.        ,  0.96296296,  1.        ,  0.96296296,  1.        ]),\n",
       " 'split6_test_score': array([ 0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333]),\n",
       " 'split6_train_score': array([ 1.        ,  1.        ,  0.98518519,  1.        ,  0.97037037,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97777778,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.99259259,\n",
       "         1.        ,  0.99259259,  1.        ,  0.98518519,  1.        ,\n",
       "         0.99259259,  1.        ,  0.98518519,  1.        ,  0.99259259,\n",
       "         1.        ,  0.99259259,  1.        ,  0.98518519,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.98518519,\n",
       "         1.        ,  0.98518519,  1.        ,  0.98518519,  1.        ,\n",
       "         0.98518519,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.96296296,  1.        ,  0.97037037,  1.        ,  0.95555556,\n",
       "         1.        ,  0.96296296,  1.        ,  0.96296296,  1.        ]),\n",
       " 'split7_test_score': array([ 1.        ,  1.        ,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ,\n",
       "         0.93333333,  1.        ,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.93333333,  1.        ,  1.        ,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ,\n",
       "         0.93333333,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
       "         1.        ,  0.93333333,  1.        ,  0.93333333,  1.        ]),\n",
       " 'split7_train_score': array([ 1.        ,  1.        ,  0.97777778,  1.        ,  0.95555556,\n",
       "         1.        ,  0.96296296,  1.        ,  0.96296296,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97037037,  1.        ,  0.97037037,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97037037,  1.        ,  0.96296296,\n",
       "         1.        ,  0.96296296,  1.        ,  0.95555556,  1.        ]),\n",
       " 'split8_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split8_train_score': array([ 1.        ,  1.        ,  0.97777778,  1.        ,  0.95555556,\n",
       "         1.        ,  0.95555556,  1.        ,  0.96296296,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.98518519,  1.        ,  0.97777778,\n",
       "         1.        ,  0.98518519,  1.        ,  0.98518519,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.97777778,  1.        ,\n",
       "         0.97777778,  1.        ,  0.97037037,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97037037,  1.        ,\n",
       "         0.96296296,  1.        ,  0.97037037,  1.        ,  0.94814815,\n",
       "         1.        ,  0.95555556,  1.        ,  0.95555556,  1.        ]),\n",
       " 'split9_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split9_train_score': array([ 1.        ,  1.        ,  0.97777778,  1.        ,  0.95555556,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97037037,  1.        ,\n",
       "         0.97037037,  1.        ,  0.97777778,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97777778,  1.        ,  0.96296296,  1.        ,\n",
       "         0.96296296,  1.        ,  0.96296296,  1.        ,  0.97777778,\n",
       "         1.        ,  0.97037037,  1.        ,  0.97777778,  1.        ,\n",
       "         0.96296296,  1.        ,  0.96296296,  1.        ,  0.95555556,\n",
       "         1.        ,  0.96296296,  1.        ,  0.94074074,  1.        ,\n",
       "         0.94814815,  1.        ,  0.94814815,  1.        ,  0.95555556,\n",
       "         1.        ,  0.95555556,  1.        ,  0.94814815,  1.        ,\n",
       "         0.94074074,  1.        ,  0.93333333,  1.        ,  0.93333333,\n",
       "         1.        ,  0.94074074,  1.        ,  0.94074074,  1.        ]),\n",
       " 'std_fit_time': array([  1.28113307e-04,   4.60223454e-05,   5.48446120e-05,\n",
       "          1.78480480e-04,   1.42079953e-04,   6.21686491e-05,\n",
       "          8.61905422e-06,   3.01708703e-05,   5.88966280e-06,\n",
       "          3.11576597e-05,   8.54870886e-05,   4.21731399e-06,\n",
       "          1.31800413e-06,   1.30583099e-05,   5.81009054e-05,\n",
       "          7.04036137e-05,   3.60674596e-06,   3.34262508e-06,\n",
       "          1.61369050e-06,   5.55387368e-06,   4.23077111e-06,\n",
       "          6.49028625e-06,   1.20277388e-06,   1.34468924e-06,\n",
       "          1.21593475e-06,   6.17978014e-06,   4.87121307e-06,\n",
       "          4.91974875e-06,   1.71263552e-06,   8.62600923e-07,\n",
       "          4.11746884e-06,   3.30095667e-06,   7.95846788e-06,\n",
       "          9.07557788e-07,   7.58189825e-06,   8.86006554e-07,\n",
       "          3.66451760e-06,   2.24620165e-06,   7.82201907e-06,\n",
       "          2.46280276e-05,   1.21434634e-04,   7.15591233e-05,\n",
       "          7.27785512e-05,   8.76724605e-05,   6.44604169e-05,\n",
       "          1.03407118e-04,   6.75549693e-06,   9.76618611e-05,\n",
       "          5.85721036e-05,   8.08072847e-05,   4.75434386e-06,\n",
       "          8.02079221e-06,   5.97931741e-06,   9.65018159e-06,\n",
       "          7.29529880e-05,   5.82424919e-06,   1.46292677e-06,\n",
       "          1.60220123e-06,   1.68266773e-06,   6.00327377e-06]),\n",
       " 'std_score_time': array([  1.52281371e-04,   5.57974052e-05,   7.23450958e-05,\n",
       "          3.21949249e-04,   2.28530813e-04,   2.45163403e-05,\n",
       "          8.64789246e-06,   1.06589105e-05,   8.35162961e-06,\n",
       "          7.46382833e-05,   1.21221441e-04,   3.42286055e-05,\n",
       "          3.47437310e-06,   2.34871345e-05,   9.80300079e-05,\n",
       "          2.58654932e-04,   6.02029337e-06,   3.98694039e-06,\n",
       "          1.29472484e-06,   2.18535567e-05,   8.65367485e-06,\n",
       "          5.62309094e-06,   2.63136787e-06,   5.00116714e-06,\n",
       "          4.50611115e-06,   4.39525152e-06,   7.91036054e-06,\n",
       "          1.54546741e-05,   6.00422057e-06,   2.48744973e-06,\n",
       "          5.07047433e-06,   4.70234941e-06,   1.51274851e-05,\n",
       "          2.69792509e-06,   1.02071001e-05,   4.42431912e-06,\n",
       "          7.73597569e-06,   5.98691792e-06,   6.95610465e-06,\n",
       "          4.06711699e-05,   2.21411016e-04,   2.19882090e-04,\n",
       "          8.48055389e-05,   2.71214900e-04,   2.32748976e-04,\n",
       "          2.40323493e-04,   1.70736019e-04,   1.39217882e-04,\n",
       "          1.58207779e-04,   1.53433100e-04,   1.13045611e-05,\n",
       "          1.42202443e-05,   4.29409269e-05,   3.43198555e-06,\n",
       "          1.46308811e-04,   1.20128189e-05,   4.18478943e-05,\n",
       "          2.96023334e-06,   6.35572240e-06,   4.98768021e-06]),\n",
       " 'std_test_score': array([ 0.05333333,  0.05333333,  0.05206833,  0.05333333,  0.04472136,\n",
       "         0.04472136,  0.04472136,  0.04472136,  0.04472136,  0.04472136,\n",
       "         0.04472136,  0.04472136,  0.04472136,  0.04472136,  0.04472136,\n",
       "         0.04472136,  0.03265986,  0.03265986,  0.04472136,  0.03265986,\n",
       "         0.04472136,  0.03265986,  0.03265986,  0.04422166,  0.0305505 ,\n",
       "         0.03265986,  0.04422166,  0.03265986,  0.03265986,  0.0305505 ,\n",
       "         0.03265986,  0.03265986,  0.03265986,  0.0305505 ,  0.0305505 ,\n",
       "         0.03265986,  0.03265986,  0.0305505 ,  0.0305505 ,  0.04472136,\n",
       "         0.03333333,  0.04472136,  0.03333333,  0.04472136,  0.03265986,\n",
       "         0.03265986,  0.04422166,  0.03265986,  0.03333333,  0.03265986,\n",
       "         0.04422166,  0.04472136,  0.04472136,  0.0305505 ,  0.04268749,\n",
       "         0.03265986,  0.04268749,  0.03265986,  0.04268749,  0.03333333]),\n",
       " 'std_train_score': array([ 0.        ,  0.        ,  0.00518519,  0.        ,  0.00744435,\n",
       "         0.        ,  0.00698813,  0.        ,  0.00725775,  0.        ,\n",
       "         0.00814815,  0.        ,  0.00592593,  0.        ,  0.00645763,\n",
       "         0.        ,  0.00645763,  0.        ,  0.00645763,  0.        ,\n",
       "         0.00814815,  0.        ,  0.0084132 ,  0.        ,  0.00578537,\n",
       "         0.        ,  0.00645763,  0.        ,  0.00296296,  0.        ,\n",
       "         0.00740741,  0.        ,  0.00573775,  0.        ,  0.00811441,\n",
       "         0.        ,  0.00573775,  0.        ,  0.01250514,  0.        ,\n",
       "         0.00996565,  0.        ,  0.01070876,  0.        ,  0.0075541 ,\n",
       "         0.        ,  0.00993808,  0.        ,  0.01120944,  0.        ,\n",
       "         0.01373869,  0.        ,  0.0143635 ,  0.        ,  0.01168869,\n",
       "         0.        ,  0.01007516,  0.        ,  0.006789  ,  0.        ])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Using the best parameters to make predictions\n",
    "Once you've found the best set of parameters using cross-validation you should retrain your model using all the data. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train your model using all data and the best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=13, weights='uniform')\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction on out-of-sample data\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortcut: GridSearchCV automatically refits the best model using all of the data\n",
    "grid.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Reducing computational expense using `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Searching many different sets of parameters at once may be computationally infeasible\n",
    "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Important:** Specify a continuous distribution (rather than a list of values) for any continous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.97333, std: 0.03266, params: {'weights': 'distance', 'n_neighbors': 16},\n",
       " mean: 0.96667, std: 0.03333, params: {'weights': 'uniform', 'n_neighbors': 22},\n",
       " mean: 0.98000, std: 0.03055, params: {'weights': 'uniform', 'n_neighbors': 18},\n",
       " mean: 0.96667, std: 0.04472, params: {'weights': 'uniform', 'n_neighbors': 27},\n",
       " mean: 0.95333, std: 0.04269, params: {'weights': 'uniform', 'n_neighbors': 29},\n",
       " mean: 0.97333, std: 0.03266, params: {'weights': 'distance', 'n_neighbors': 10},\n",
       " mean: 0.96667, std: 0.04472, params: {'weights': 'distance', 'n_neighbors': 22},\n",
       " mean: 0.97333, std: 0.04422, params: {'weights': 'uniform', 'n_neighbors': 14},\n",
       " mean: 0.97333, std: 0.04422, params: {'weights': 'distance', 'n_neighbors': 12},\n",
       " mean: 0.97333, std: 0.03266, params: {'weights': 'uniform', 'n_neighbors': 15}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "rand.fit(X, y)\n",
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'weights': 'uniform', 'n_neighbors': 18}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.973, 0.98, 0.98, 0.98, 0.98, 0.973, 0.98, 0.973, 0.98, 0.973, 0.98, 0.98, 0.98, 0.973]\n",
      "[{'weights': 'uniform', 'n_neighbors': 18}, {'weights': 'distance', 'n_neighbors': 17}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'uniform', 'n_neighbors': 18}, {'weights': 'distance', 'n_neighbors': 27}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'distance', 'n_neighbors': 12}, {'weights': 'distance', 'n_neighbors': 27}, {'weights': 'distance', 'n_neighbors': 15}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'distance', 'n_neighbors': 17}, {'weights': 'distance', 'n_neighbors': 29}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'distance', 'n_neighbors': 10}, {'weights': 'distance', 'n_neighbors': 19}, {'weights': 'distance', 'n_neighbors': 24}, {'weights': 'distance', 'n_neighbors': 19}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'uniform', 'n_neighbors': 13}, {'weights': 'uniform', 'n_neighbors': 16}]\n"
     ]
    }
   ],
   "source": [
    "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "params = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "    params.append(rand.best_params_)\n",
    "    \n",
    "print(best_scores)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Resources\n",
    "\n",
    "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)\n",
    "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html)\n",
    "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
    "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 3: Evaluating classifier performance, I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Classification accuracy\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692708333333\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print(TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](images/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692708333333\n",
      "0.692708333333\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.307291666667\n",
      "0.307291666667\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.241935483871\n",
      "0.241935483871\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907692307692\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0923076923077\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555555555556\n",
      "0.555555555556\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
