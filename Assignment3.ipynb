{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Machine Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "The purpose of this assignment is to get you more familiar with scikit-learn. Using the same principles from **Lab 3a** and **Lab 3b**, you'll be building a classifier that, given a list of tumor biopsy features, will determine whether a breast tumor is malignant or benign!\n",
    "\n",
    "The dataset is from the Breast Cancer Wisconsin Diagnostic Database.  It is a classic in that has been used in many machine learning and statistics courses.  \n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Preparing the data\n",
    "\n",
    "To train a machine learning model, we first need data. The dataset we'll be using is located in `data/breastcancer_data.csv`\n",
    "\n",
    "Here is what each column of the file represents, as well as its domain.\n",
    "\n",
    "            Attribute                 Domain\n",
    "    1. Sample code number            id number\n",
    "    2. Clump Thickness               1 - 10\n",
    "    3. Uniformity of Cell Size       1 - 10\n",
    "    4. Uniformity of Cell Shape      1 - 10\n",
    "    5. Marginal Adhesion             1 - 10\n",
    "    6. Single Epithelial Cell Size   1 - 10\n",
    "    7. Bare Nuclei                   1 - 10\n",
    "    8. Bland Chromatin               1 - 10\n",
    "    9. Normal Nucleoli               1 - 10\n",
    "    10. Mitoses                       1 - 10\n",
    "    11. Class:                        (2 for benign, 4 for malignant)\n",
    "    \n",
    "   \n",
    "Unless you have a background in biology, you may not be familiar with what each of these attributes means. As data scientists, however, you're able to recognize that some attributes will be more useful than others in training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Task 1**: Load the data\n",
    "Read in the breast cancer data from the CSV file and create a dataframe using `pandas.\n",
    "`. Print the first five rows.  Produce a summary of the data.\n",
    "\n",
    "**NOTE:** The csv file we provide has no header. Notice that if you use the [pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function from Pandas without specifying the `names` parameter, it takes the first row of the data as the column names. This is not what we want!\n",
    "\n",
    "Instead, pass in a list of column names in your call to `read_csv`. Finally, store the result in a variable named `df`.\n",
    "\n",
    "Hint: Use the following [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) methods:\n",
    "* To print out the first n (5, by default) rows, use 'DataFrame.head(n=5)'. \n",
    "* Use 'DataFrame.describe()' to produce a nice data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# names = ...\n",
    "# df = ...\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Task 2:** Using lab3a and lab3b as a reference, answer the following questions\n",
    "\n",
    "1. Which attributes in your data will you include in the model? In other words, which attributes above will be your **features**?\n",
    "\n",
    "2. Which attributes will you not include in the model? Why?\n",
    "\n",
    "3. What is the **target**/**response**, the attribute we are trying to predict? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**PUT YOUR ANSWER HERE**\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use scikit-learn to train a model based on our data, we need the data to be in the format scikit-learn requests.\n",
    "\n",
    "From lab3a, recall the following requirements for working with data in scikit-learn:\n",
    "\n",
    "#### Requirements for working with data in scikit-learn\n",
    "\n",
    "1. Features and response are **separate objects**\n",
    "2. Features and response should be **numeric**\n",
    "3. Features and response should be **NumPy arrays**\n",
    "4. Features and response should have **specific shapes**\n",
    "\n",
    "\n",
    "All of our data is in a single dataframe. We don't satisfy the first requirement, and thus, none of the following requirements.\n",
    "\n",
    "### **Task 3:** Separate your dataframe into two NumPy arrays\n",
    "You will be creating two new NumPy arrays, *data* and *target*. Use your answers to Task 2 to guide you. Are there any columns in the dataframe you can ignore?\n",
    "\n",
    "**Hints:**\n",
    "* The target values are in the `class` column.\n",
    "* Panda's dataframes store tabular data internally using 'numpy' arrays.  You can access this data directly using `Dataframe.values`\n",
    "\n",
    "If you're confused, look at **Lab 3a** as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you may consider df.pop('id'), but there are other ways to select columns too!\n",
    "\n",
    "# get every column except class and id, then convert that dataframe into a numpy array\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Test cases, do not change!\n",
    "assert(683, 9) == data.shape\n",
    "assert(683,) == target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2: Training machine learning models\n",
    "\n",
    "Now that your data is in the correct format for using scikit-learn, you can use `sklearn`'s built in classification models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we'll be using [Decision Trees](http://scikit-learn.org/stable/modules/tree.html) to perform binary classification.\n",
    "\n",
    "### **Task 4:** Train and test your classifier on training data\n",
    "Train and test your classifier on all of your data and test its accuracy on the same data.\n",
    "\n",
    "For this task, you'll first need to initialize your classifier by creating an instance of it and then calling the `fit` method to train it.\n",
    "\n",
    "\n",
    "Hint: To test the model's accuracy, use [sklearn.metrics.accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
    "\n",
    "Look at **Lab 3a** for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# usually we use X to denote training features, and y to denote training targets\n",
    "X = data\n",
    "y = target\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "# tree = ...\n",
    "\n",
    "# fit the model using the entire dataset\n",
    "\n",
    "# find the accuracy score of your model by testing it on the entire dataset, again\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have been surprised after printing out your accuracy score in **Task 4**. \n",
    "\n",
    "### **Task 5:** What are the drawbacks to training and testing your classifier on the entire dataset? \n",
    "\n",
    "Please write your response in the context of the breast cancer dataset we're using."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**PUT YOUR ANSWER HERE**\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "Instead of simply training and testing your classifier on the entire dataset, you can perform a technique called **K-fold cross validation**. \n",
    "\n",
    "K-fold cross validation splits your dataset into K chunks. Then, for each chunk, it fits and scores the classifier using all the other chunks as the **training set** and the current chunk as the **test set**. We then treat the average of all the scores as the total score of the model.  This provides a more accurate estimate of how your classifier will perform in the real world (i.e. with new data).\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)\n",
    "\n",
    "### **Task 6**: Use cross-validation on your decision tree classifier.\n",
    "Using [sklearn.model_selection.cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), perform 10-fold cross-validation on your decision tree classifier.\n",
    "\n",
    "Print the average of all the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 3: Hyperparameter tuning\n",
    "\n",
    "The focus for this assignment will be in Grid Search, which you will be implementing from scratch.\n",
    "\n",
    "See the link below for more information:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)#Grid_search\n",
    "\n",
    "In machine learning, there are parameters that the data scientist can set before training their model. These parameters are called **hyperparameters**. \n",
    "\n",
    "Decision trees have many such parameters, such as `max_features`, `max_depth`, and `min_samples_leaf`. This makes Decision trees perfect for using procedures such as [grid search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or [randomized search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), which find better hyperparameters by maximizing cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Although Grid Search may sound complicated, it can typically be implemented in just a few lines of code.\n",
    "\n",
    "Consider the pseudocode for Grid Search below, which finds the optimal combination of two parameters: `max_features` and `max_depth`. (Note: these are both features in sklearn's DecisionTreeClassifier).\n",
    "\n",
    "```\n",
    "    maxFeaturesList = list of \"reasonable\" values for max_features\n",
    "    maxDepthList = list of \"reasonable\" values for max_depth\n",
    "    \n",
    "    for max_features in maxFeaturesList:\n",
    "        for max_depth in maxDepthList:\n",
    "            if crossValidation(tree(max_features, max_depth)) is highest yet:\n",
    "                bestMaxFeatures = max_features\n",
    "                bestMaxDepth = max_depth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 7**: Implement Grid Search \n",
    "Improved your classifier by coding a grid search algorithm to find the better hyperparameter values for `max_features`, `max_depth`, and `min_samples_leaf`.\n",
    "\n",
    "You are responsible for creating a \"reasonable\" set of values for each hyperparameter. Read the documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for some ideas.\n",
    "\n",
    "**DO NOT** use `sklearn.model_selection.GridSearchCV`. You can, however, use `cross_val_score` to evaluate the score at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hints: \n",
    "Initialize a list of reasonable values for each hyperparemeter\n",
    "* maxFeaturesList = ...\n",
    "* maxDepthList = ...\n",
    "* minSamplesLeafList = ...\n",
    "\n",
    "Then train and test your DecisionTreeClassifier using all possible \n",
    "combinations of the selected parameters. This will require \n",
    "len(maxFeatureList)*len(maxDepthList)*len(minSampleLeafList) \n",
    "train and test steps\n",
    "\n",
    "\n",
    "Print the best set of hyperparemeters and the score obtained \n",
    "using those hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of grid search finds hyperparemeters that achieve a cross validation score of 95%. In theory, our classifier would almost always classify tumors correctly. But how often would you classify a benign tumor as malignant? And how often would you classify a malignant tumor as benign?\n",
    "\n",
    "### **Task 8**:  Confusion Matrix\n",
    "Using the classifier with optimal hyperparameters, construct a confusion matrix that describes its performance\n",
    "\n",
    "Read documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to see how to build a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "We've provided code that splits the dataset into a training set and a test set. Call `fit` using the training set, and then call `predict` and construct the confusion matrix using the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# print your confusion matrix here\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 9**: Describe your confusion matrix.\n",
    "\n",
    "What does each value in your confusion matrix correspond to?\n",
    "\n",
    "Identify what the following terms mean in regards to the breast cancer dataset:\n",
    "\n",
    "- **True Positives (TP):** \n",
    "- **True Negatives (TN):** \n",
    "- **False Positives (FP):** \n",
    "- **False Negatives (FN):** \n",
    "\n",
    "In the context of diagnosing breast cancer, is it worse to have a false positive or a false negative? Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**YOUR SOLUTION HERE**\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Mini-project\n",
    "Perform the same set of classification tasks in Tasks 1 through 9 on a either the [Titanic dataset](https://www.kaggle.com/c/titanic) or a dataset of your choosing.  Use your data from a source other than sklearn.  Include a set of next steps (i.e. suggestions) on how you could improve your classifiers performance.\n",
    "\n",
    "Hints:\n",
    "1. Be careful during data preparation to handle missing values appropriately.  You can either fill them in with estimate (say by the mean of the ones that are present), or you can drop rows or columns that contain them.\n",
    "3. You will need to either drop columns that contain categorical data (unordered data) or convert them to numerical form.\n",
    "2. Converting categorical data (unordered category data) to numerical form requires using [One Hot Encoding](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/) or some other appropriate technique.  Here is some [discussion](http://pbpython.com/categorical-encoding.html)\n",
    "3. Use the Z-transform functionality in sklean to convert continuous values to z-scores and use them appropriately. Read this general information on [sklearn preprocessing]( http://scikit-learn.org/stable/modules/preprocessing.html) and then use [sklearn.preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
       "# Your solution here.  Please include additional cells as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}